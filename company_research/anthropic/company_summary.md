# Company Research: Anthropic

**Researched:** 08-01-26
**Primary URL:** https://www.anthropic.com

---

## Company Overview

- **Full Name:** Anthropic PBC (Public Benefit Corporation)
- **Industry:** Artificial Intelligence / AI Safety and Research
- **Founded:** 2021
- **Headquarters:** 548 Market St, San Francisco, California, USA
- **Size:** 1,000 - 5,000+ employees (rapidly growing)
- **Stage:** Late-stage private (valued at $183B in Sept 2025, targeting $350B in Jan 2026)
- **Business Model:** B2B and B2C - AI products (Claude), API platform, enterprise solutions

## What They Do

Anthropic is an AI safety and research company that builds reliable, interpretable, and steerable AI systems. They develop Claude, an AI assistant designed to be helpful, honest, and harmless. The company conducts frontier AI research, develops safety techniques, and deploys AI systems through products and partnerships across multiple platforms including their own API, Amazon Bedrock, and Google Cloud's Vertex AI.

## Mission & Vision

**Mission:**
> "Building systems that people can rely on and generating research about the opportunities and risks of AI."

Anthropic believes AI will have a vast impact on the world and is dedicated to building frontier AI systems that are reliable, interpretable, and steerable while treating AI safety as a systematic science.

**Vision:**
To be a safety-first company that ignites a "race to the top" on AI safety, constantly setting the industry bar for AI safety and security while ensuring AI technology becomes a robustly positive force for humanity.

## Core Values

1. **Act for the global good:** Make decisions that maximize positive outcomes for humanity in the long run. Take bold actions to ensure technology is a positive force.

2. **Hold light and shade:** Recognize AI's potential for both unprecedented risks and unprecedented benefits. Need shade to protect against bad outcomes and light to realize good ones.

3. **Be good to our users:** Define "users" broadly (customers, policymakers, employees, anyone impacted). Cultivate generosity and kindness in all interactions. Going above and beyond is meeting expectations.

4. **Ignite a race to the top on safety:** As a safety-first company, building reliable, trustworthy, and secure systems is a collective responsibility. Work to inspire competitors to develop safe and secure AI systems.

5. **Do the simple thing that works:** Take an empirical approach, care about impact not sophistication. Identify the simplest solution and iterate. "Don't invent a spaceship if all we need is a bicycle."

6. **Be helpful, honest, and harmless:** High-trust, low-ego organization. Communicate kindly and directly, assuming good intentions. Avoid harm and repair relationships when needed. Everyone contributes regardless of role.

7. **Put the mission first:** The mission is the shared purpose that allows swift collective action. It engenders trust, collaboration, and is the final arbiter in decisions. Everyone takes personal ownership over mission success.

## Culture & Work Environment

- **Work Style:** Primarily office-based in San Francisco Bay Area with some flexibility. Most staff come to the office regularly; some live further away and come in for one week a month. Flexible during relocation transitions.
- **Culture Traits:** High-trust, low-ego, mission-driven, intellectually curious, collaborative, unpretentious, transparent. Described as intense but fulfilling work environment.
- **Team Composition:** Interdisciplinary - researchers, engineers, policy experts, business leaders, and operators from diverse backgrounds (NASA, startups, armed forces, academia).
- **Hiring Philosophy:** "We care about what you can do, not where you learned to do it." About half of technical staff had no prior ML experience; about half have PhDs, but many brilliant colleagues never went to college.
- **Perks/Benefits:**
  - Comprehensive health, dental, vision insurance
  - 22 weeks paid parental leave
  - Inclusive fertility benefits (Carrot Fertility)
  - Competitive salary and equity packages
  - Optional equity donation matching (1:1 ratio, up to 25% of equity)
  - $500/month flexible wellness and time-saver stipend
  - Annual education stipend
  - Home office stipends
  - Daily meals and snacks in office
  - Relocation support
  - Retirement plans with competitive matching
  - Mental health support

- **Reputation:** Glassdoor rating of 4.4/5 stars; 95% of employees would recommend working there; 4.9/5 for culture and values; 4.8/5 for compensation and career opportunities.

## Technology Stack

- **Languages:** Python (primary for ML), JavaScript/TypeScript (frontend)
- **Frontend:** React, Next.js, Tailwind CSS, Streamlit
- **Infrastructure:** Multi-cloud (AWS, GCP), Kubernetes
- **Hardware:** TPU (moving to ~1 million Google TPUv7 units), GPU, AWS Trainium
- **Development Tools:** Coder for remote development, Claude Code for internal development
- **Notable:** Moving toward vertical integration with directly owned data center infrastructure via partnerships with TeraWulf, Hut8, and Cipher Mining

**Confidence:** MEDIUM-HIGH (from engineering blog, job postings, news reports)

## Security Context

**Security Team & Leadership:**
- **CISO:** Vitaly Gudanets (former Netflix cybersecurity boss, previously VP of Security Engineering at Google)
- **Deputy CISO:** Jason Clinton (former CISO)
- Security team is actively expanding with hiring across incident response, container and VM security, and cloud security architecture

**Security Philosophy:**
> "We understand our top risks. We actively address them. And we're non-blocking... we never want to be the organization of 'no.' Secure by default, private by design - with as little friction as possible."
> - Vitaly Gudanets, CISO

**Security Practices:**
- **AI-Powered SOC:** Anthropic has built an AI SOC powered end-to-end by Claude - a radically reimagined security operation designed for speed, volume, and resilience. They no longer operate a traditional security operations center.
- **Access Control:** Role-based access control model, enterprise identity provider with strong password policies, MFA using app-based tokens
- **Data Protection:** Comprehensive security controls for training data, PII minimization, data provenance tracking, restricted access with detailed logging
- **Change Management:** Formal change management with documented procedures, technical and security review, comprehensive testing before deployment
- **Compliance:** SOC 2 Type 2 certified

**AI Safety Levels (ASL) Framework:**
- ASL-1: Systems with no meaningful catastrophic risk
- ASL-2: Systems showing early signs of dangerous capabilities (current Claude models)
- ASL-3: Systems that substantially increase catastrophic misuse risk
- Claude Opus 4 launched with ASL-3 Deployment and Security Standards activated

**Responsible Scaling Policy:**
Anthropic maintains a core commitment to not train or deploy models unless they have implemented safety and security measures that keep risks below acceptable levels. This framework is overseen by the Responsible Scaling Officer (currently Jared Kaplan, Co-Founder and Chief Science Officer).

## Recent Developments

- **January 2026:** Signed term sheet for $10 billion funding round at $350 billion valuation, led by Coatue and GIC (Singapore sovereign wealth fund)
- **November 2025:** Microsoft invested up to $5 billion, Nvidia invested up to $10 billion, pushing valuation to ~$350 billion range
- **September 2025:** Completed $13 billion Series F at $183 billion valuation, led by ICONIQ
- **August 2025:** Annual run-rate revenue reached over $5 billion (up from $1B at start of 2025)
- **May 2025:** Claude Code full launch - now generating over $500 million in run-rate revenue
- **2025:** Launched Claude Opus 4 with ASL-3 security protections activated
- **2025:** Hired Vitaly Gudanets as CISO from Netflix
- **July 2025:** Accepted $200M defense contract from U.S. Department of Defense

## Leadership

| Role | Name | Notable |
|------|------|---------|
| CEO | Dario Amodei | Co-founder, former VP of Research at OpenAI, Forbes-estimated worth ~$3.7B |
| President | Daniela Amodei | Co-founder, former VP of Operations at OpenAI |
| Chief Science Officer | Jared Kaplan | Co-founder, also serves as Responsible Scaling Officer |
| CTO | Sam McCandlish | Co-founder, former Responsible Scaling Officer |
| CISO | Vitaly Gudanets | Former Netflix cybersecurity boss, 30+ years security experience |
| Deputy CISO | Jason Clinton | Former Anthropic CISO |

**Board of Directors:** Dario Amodei, Daniela Amodei, Yasmin Razavi, Jay Kreps, Reed Hastings

**Long-Term Benefit Trust Trustees:** Neil Buddy Shah, Kanika Bahl, Zach Robinson, Richard Fontaine

## Quotes & Soundbites

> "I think I'm deeply uncomfortable with these decisions being made by a few companies, by a few people."
> - Dario Amodei, CEO, on AI governance (November 2025, CBS 60 Minutes)

> "I think at the end of the day, I warn about these things not to be a prophet of doom, but because warning about them is the first step towards solving them."
> - Dario Amodei, CEO (December 2025, NYT DealBook Summit)

> "It's eerie the extent to which the broader public and politicians, legislators, I don't think, are fully aware of what's going on."
> - Dario Amodei, CEO (May 2025, CNN)

> "We understand our top risks. We actively address them. And we're non-blocking... we never want to be the organization of 'no.' Secure by default, private by design - with as little friction as possible."
> - Vitaly Gudanets, CISO

> "Shaping the future of AI and, in turn, the future of our world is a responsibility and a privilege."
> - Anthropic Company Values

## Products & Services

**Consumer Products:**
- Claude (AI assistant) - available via web, iOS, Android apps
- Claude Code (agentic coding tool)
- Claude in Chrome, Excel, Slack integrations

**Developer Platform:**
- Claude API with multiple model tiers: Opus (most capable), Sonnet (balanced), Haiku (fastest)
- Available on Amazon Bedrock and Google Cloud's Vertex AI

**Enterprise:**
- Team and Enterprise plans
- Custom solutions for financial services, government, life sciences, education, nonprofits

## Keywords for Application

Use these terms/phrases that appear frequently in company communications:

- AI safety
- Reliable, interpretable, steerable
- Helpful, honest, harmless
- Responsible Scaling Policy
- Race to the top (on safety)
- Frontier AI / frontier research
- Mission-driven
- High-trust, low-ego
- Safety as a science
- Global good
- ASL (AI Safety Levels)
- Secure by default, private by design
- Model weights security
- CBRN risk mitigation
- Interdisciplinary collaboration

---

## Research Metadata

### Sources Consulted

| Source | URL/Path | Status | Confidence |
|--------|----------|--------|------------|
| Provided: Company _ Anthropic.pdf | local file | Processed | HIGH |
| Provided: Careers _ Anthropic.pdf | local file | Processed | HIGH |
| CNBC - Anthropic funding news | https://www.cnbc.com/2026/01/07/anthropic-funding-term-sheet-valuation.html | Retrieved | MEDIUM-HIGH |
| Anthropic RSP announcement | https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy | Retrieved | HIGH |
| National CIO Review - CISO hire | https://nationalcioreview.com/cxos-on-the-move/anthropic-expands-security-team-with-ciso-hire-from-netflix/ | Retrieved | MEDIUM-HIGH |
| The Stack - Security hiring | https://www.thestack.technology/anthropic-new-ciso-claude-cyber-attack/ | Retrieved | MEDIUM-HIGH |
| Drata - CISO interview | https://drata.com/blog/drataverse-future-of-grc | Retrieved | MEDIUM |
| Dropzone AI - Claude SOC | https://www.dropzone.ai/blog/anthropics-claude-powered-soc-a-cool-build-that-only-an-ai-company-could-pull-off | Retrieved | MEDIUM |
| Anthropic Engineering | https://www.anthropic.com/engineering | Retrieved | HIGH |
| Glassdoor Reviews | https://www.glassdoor.com/Reviews/Anthropic-Reviews-E8109027.htm | Retrieved | MEDIUM |
| Fortune - Dario Amodei interview | https://fortune.com/2025/11/17/anthropic-ceo-dario-amodei-ai-safety-risks-regulation/ | Retrieved | MEDIUM |
| Wikipedia - Dario Amodei | https://en.wikipedia.org/wiki/Dario_Amodei | Retrieved | MEDIUM |
| Goldman Sachs - Series F | https://am.gs.com/en-us/individual/news/press-release/2025/anthropic | Retrieved | HIGH |

### Confidence Assessment

| Section | Confidence | Basis |
|---------|------------|-------|
| Company Overview | HIGH | Official website, provided PDFs |
| Mission & Values | HIGH | Official website, provided PDFs |
| Culture | HIGH | Official careers page, Glassdoor reviews |
| Tech Stack | MEDIUM-HIGH | Engineering blog, news articles, job postings |
| Security Context | HIGH | CISO interviews, official documentation, news reports |
| Recent Developments | HIGH | Multiple news sources, official announcements |
| Leadership | HIGH | Official website, news articles |
| Products | HIGH | Official website |

### Information Gaps

- Specific details about internal security team structure and size
- Detailed breakdown of security certifications beyond SOC 2 Type 2
- Specific technologies used in their AI-powered SOC

### Research Limitations

- Some Glassdoor reviews may reflect outdated information given rapid company growth
- Employee count varies significantly across sources due to rapid hiring
- Some security practices details are intentionally not publicly disclosed

---

## Security-Specific Relevance for Application

For a Software Security Engineer role at Anthropic, key points to emphasize:

1. **AI-Native Security:** Anthropic has built a Claude-powered SOC, showing they embrace AI in security operations
2. **Expanding Security Team:** Actively hiring across incident response, container/VM security, and cloud security architecture
3. **Security Leadership:** Strong CISO leadership from Vitaly Gudanets with Google and Netflix background
4. **Safety-First Culture:** Security is deeply embedded in company values ("Ignite a race to the top on safety")
5. **ASL Framework:** Unique AI Safety Level framework requires deep security implementation
6. **Multi-Cloud Environment:** Operates across AWS and GCP with complex infrastructure
7. **Model Weights Protection:** Critical focus on preventing theft of proprietary model weights
8. **Responsible Disclosure Policy:** Company maintains formal security disclosure processes
9. **High-Stakes Environment:** Protecting frontier AI research and infrastructure from nation-state threats

The security team operates with the philosophy of being "non-blocking" and enabling - "secure by default, private by design - with as little friction as possible" - which suggests they value security professionals who can balance protection with developer experience.
