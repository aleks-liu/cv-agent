# Why I Want to Join OpenAI

There's a particular weight to securing technology that might fundamentally change human capability. OpenAI's Charter doesn't hedge on this—it commits to ensuring AGI benefits all of humanity, even if that means prioritizing safety over competitive advantage. That's not corporate language. That's a statement about what kind of organization this is.

## Alignment with OpenAI's Mission

The Charter's commitment to "broad benefit" resonates with why I chose security as a career. Detection and response work is ultimately about protecting people—users who trust platforms with their data, employees who rely on infrastructure, and in OpenAI's case, humanity placing faith in responsible AI development. Your Safety and Security Committee, with independent board oversight, signals that this isn't performative. Security at OpenAI isn't a compliance checkbox; it's foundational to the mission.

I appreciate that OpenAI values acting with humility—recognizing the limits of knowledge while building unprecedented technology. In detection engineering, humility means acknowledging that adversaries will find gaps you didn't anticipate, that yesterday's detections might miss today's techniques, and that the work is never finished. That mindset of continuous updating is how I've approached every monitoring system I've built.

## What Excites Me About OpenAI's Security Work

The Sydney office opening as part of "OpenAI for Australia" represents more than geographic expansion—it's extending the security perimeter to new infrastructure, new threat landscapes, and new regulatory contexts. Building detection capabilities for a rapidly scaling organization, across Azure and AWS environments, while the underlying technology itself evolves monthly, is exactly the kind of complex, high-stakes problem I want to solve.

More specifically, the opportunity to use AI to improve security posture—something explicitly mentioned in the role description—connects directly to work I'm already doing. Developing LLM-powered security tools has shown me both the potential and the limitations. Bringing that experience to a team that's building the models themselves would accelerate what's possible.

## What I Bring

Beyond the technical match—SIEM expertise, detection rule development, endpoint visibility, automation—I bring the perspective of someone who has built monitoring infrastructure from zero across different organizational scales. I understand the tradeoffs between alert volume and signal clarity, between comprehensive logging and operational overhead, between security controls and researcher productivity. That last tension seems particularly relevant at OpenAI, where your Security team tenet explicitly includes "enabling researchers."

I've worked at companies navigating intense external scrutiny (Kaspersky during geopolitical pressures, VK during platform controversies). OpenAI operates under perhaps the most sustained public attention of any technology company today. I understand what it means to maintain security discipline when every decision might face external examination.

## Looking Forward

Sam Altman noted that this is a three-year-old technology adopted faster than anything in history. The rate of change is unprecedented—and so are the security implications. I want to be part of the team ensuring that as OpenAI ships transformative capabilities, the security infrastructure scales with them.

The mission matters. The work is hard. I'm ready.

Aleksandr Liukov
