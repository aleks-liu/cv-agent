# Why I Want to Join Anthropic

I have spent my career building security into products and systems. Over the past year, I have also started building with AI—developing tools that use large language models to analyze code for vulnerabilities and automate security triage. This work has made me think carefully about what it means to secure AI systems and, more broadly, what it means to build AI that is safe and reliable. Anthropic is where these concerns are taken most seriously.

Anthropic's approach to security resonates with how I think about the problem. Your CISO's stated philosophy—"secure by default, private by design, with as little friction as possible"—describes what good product security should be. Security that blocks and frustrates is security that gets bypassed. I have spent years learning to work with engineering teams rather than against them: conducting design reviews early, building tooling that integrates into existing workflows, and writing requirements that developers can actually implement. The goal is always to make secure development the path of least resistance.

I am particularly interested in the security challenges specific to AI products. Prompt injection, data poisoning, model extraction—these are problems that don't map neatly onto traditional application security frameworks. They require new thinking. Anthropic's Responsible Scaling Policy and ASL framework represent a systematic attempt to reason about AI risks, and the Application Security team sits at the intersection of traditional software security and these novel challenges. That intersection is where I want to work.

I have built vulnerability management programs, security pipelines, and internal security tooling. I understand what it takes to scale security practices across a growing engineering organization. Anthropic is growing rapidly and shipping products that millions of people rely on. I want to help ensure that growth happens securely.

Aleksandr Liukov
