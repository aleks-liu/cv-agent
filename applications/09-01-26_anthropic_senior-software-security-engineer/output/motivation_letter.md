# Why I Want to Join Anthropic

I've spent over a decade building security systems, and for most of that time, I operated under a straightforward assumption: protect the organization from external threats, secure the data, harden the perimeter. But something shifted in the past two years as I began developing AI-powered security tools. Watching an LLM reason through code vulnerabilities made me realize that AI systems aren't just another asset to protect—they're a fundamentally new kind of entity that will reshape what security even means.

## Alignment with Anthropic's Mission

Anthropic's framing of AI safety as "a systematic science" rather than a compliance checkbox resonates with how I've always approached security engineering. Your value of "acting for the global good" isn't corporate boilerplate—it's visible in decisions like maintaining the Responsible Scaling Policy and the ASL framework, which treat capability growth and safety investment as inseparable. The fact that you've structured as a Public Benefit Corporation suggests that safety isn't just a PR strategy but a governance commitment.

What particularly draws me is the stated goal of igniting "a race to the top on safety." In traditional security, we often feel like we're playing defense against an industry that deprioritizes protection. At Anthropic, security isn't just protecting a product—it's advancing the very mission the company exists to fulfill.

## What Excites Me About Your Work

Your CISO Vitaly Gudanets described Anthropic's security philosophy as "secure by default, private by design—with as little friction as possible." This is exactly the approach I've spent years advocating for: security that empowers rather than obstructs. The fact that you've built an AI-powered SOC with Claude demonstrates a willingness to apply your own technology to internal operations—treating security as a first-class engineering problem rather than a cost center.

I'm also fascinated by the challenge of protecting model weights and training infrastructure against sophisticated threat actors. This isn't standard enterprise security—it's securing intellectual property that could define the next decade of technological development.

## What I Bring

Beyond my technical experience in Kubernetes hardening, CI/CD security, and infrastructure automation, I bring a perspective shaped by building security programs from scratch in fast-moving environments. I understand that security at a company like Anthropic must scale with engineering velocity, and I've spent years developing the automation-first mindset needed to achieve that. My recent work developing AI-assisted security tools also means I arrive with genuine technical intuition about how LLMs behave—useful when protecting AI systems from emerging threats.

---

I want to work on problems that matter, and I believe the security challenges facing frontier AI development are among the most consequential of our time. Anthropic is where those challenges meet the resources, talent, and mission focus needed to address them seriously.
