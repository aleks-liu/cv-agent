# Why I Want to Join Anthropic

I have spent the past year integrating AI into my security work — building tools that use LLMs to analyze code for vulnerabilities and automate the triage of security findings. This experience has shown me that AI fundamentally changes what is possible in security operations. When I learned that Anthropic has built an AI-powered SOC that replaces the traditional security operations model, I recognized this is the direction I want to pursue.

What draws me to Anthropic specifically is the approach to security expressed by your CISO: "secure by default, private by design — with as little friction as possible." This matches how I think about security. At every company I have worked at, I have tried to build security that enables rather than blocks — automated pipelines, self-service tooling, security controls embedded in infrastructure. The Detection Platform team appears to embody this philosophy at scale.

I am also motivated by the stakes involved. Anthropic is building frontier AI systems that require frontier security. The ASL framework and the focus on protecting model weights represent security challenges that do not exist elsewhere. Working on detection infrastructure for an AI company building Claude means the security work itself advances AI safety.

My background is in security monitoring and platform development rather than pure software engineering. I have built log pipelines, detection queries, and security tooling — but building ML-powered detection systems at Anthropic's scale would require me to grow. I am drawn to that challenge. The intersection of security domain expertise and engineering infrastructure is exactly where I want to develop.

Anthropic's mission to build AI that is safe and beneficial is not abstract to me. I use Claude daily and see firsthand how it changes what is possible. Contributing to the security infrastructure that protects this work would be meaningful.
